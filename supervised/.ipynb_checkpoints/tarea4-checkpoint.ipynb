{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/aldo/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /home/aldo/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/aldo/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The pgf.debug rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /home/aldo/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/aldo/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "# Funciones auxiliares\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.preprocessing as pr\n",
    "if not(os.path.isdir(\"tarea\")):\n",
    "    mkdir(\"tarea\")\n",
    "def dataScaled(df):\n",
    "    cat = [var for var in df.columns if not(np.issubdtype(df[var].dtype,np.number))]\n",
    "    num = df.drop(cat,axis=1)\n",
    "    # Creating dictionary to store the different data frames\n",
    "    data = {\"original\":df}\n",
    "    # Standarizing data to have mean 0 and variance 1\n",
    "    scaler = pr.StandardScaler()\n",
    "    scaler.fit(num)\n",
    "    data[\"standarized\"] = pd.DataFrame(scaler.transform(num),index=num.index,columns=num.columns)\n",
    "    data[\"standarized\"][cat] = df[cat]\n",
    "    data[\"standarized\"] = data[\"standarized\"][df.columns]\n",
    "    # Centering data to have variance 1 \n",
    "    scaler = pr.StandardScaler(with_mean=False)\n",
    "    scaler.fit(num)\n",
    "    data[\"withmean\"] = pd.DataFrame(scaler.transform(num),index=num.index,columns=num.columns)\n",
    "    data[\"withmean\"][cat] = df[cat]\n",
    "    data[\"withmean\"] = data[\"withmean\"][df.columns]\n",
    "    return data\n",
    "\n",
    "def boxcoxLambdaTable(df,resCol,alpha=0.05):\n",
    "    names = []\n",
    "    lambdas = []\n",
    "    intervalsBot = []\n",
    "    intervalsTop = []\n",
    "    for col in df.columns:\n",
    "        if col != resCol and np.issubdtype(df[col].dtype,np.number):\n",
    "            if (df[col]>0).prod():\n",
    "                names.append(col)\n",
    "                bx = boxcox(df[col],alpha=alpha)\n",
    "                lambdas.append(bx[1])\n",
    "                intervalsBot.append(bx[2][0])\n",
    "                intervalsTop.append(bx[2][1])\n",
    "            else:\n",
    "                print(\"Can't convert column {0}: not entirely positive\".format(col) )\n",
    "    fin = pd.DataFrame.from_dict({\"lambda\":lambdas,\"Lower confidence interval, alpha = {0}\".format(alpha):intervalsBot,\"Upper confidence interval, alpha = {0}\".format(alpha):intervalsTop})\n",
    "    fin.index = names\n",
    "    return fin.transpose()\n",
    "\n",
    "def bootstrap(df):\n",
    "    return resample(df,n_samples=df.shape[0]).reset_index(drop=True)\n",
    "\n",
    "def KFold_strat(X,y,**kwargs):\n",
    "    splitter = ms.StratifiedKFold(**kwargs)\n",
    "    iterator = splitter.split(X,y)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for train_index, test_index in iterator:\n",
    "        X_train.append(X.iloc[train_index,:])\n",
    "        y_train.append(y.iloc[train_index])\n",
    "        X_test.append(X.iloc[test_index,:])\n",
    "        y_test.append(y.iloc[test_index])\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def KFold(X,y,**kwargs):\n",
    "    splitter = ms.KFold(**kwargs)\n",
    "    iterator = splitter.split(X,y)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for train_index, test_index in iterator:\n",
    "        X_train.append(X.iloc[train_index,:])\n",
    "        y_train.append(y.iloc[train_index])\n",
    "        X_test.append(X.iloc[test_index,:])\n",
    "        y_test.append(y.iloc[test_index])\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def apparentErrorRate(mod,df,resCol):\n",
    "    X = df.drop(resCol,axis=1)\n",
    "    y = df[resCol]\n",
    "    fit = mod.fit(X,y)\n",
    "    res = fit.predict(X)\n",
    "    fin = np.mean(y != res)\n",
    "    classes = list(set(y))\n",
    "    perClass = np.zeros(len(classes))\n",
    "    for j,val in enumerate(classes):\n",
    "        curr = X[y==val]\n",
    "        res = fit.predict(curr)\n",
    "        perClass[j] = np.mean(y[y==val] != res)\n",
    "    final = [fin]\n",
    "    final.extend(perClass)\n",
    "    return final,[0 for f in final]\n",
    "\n",
    "def trainTestErrorRates(mod,df,resCol,n=100,size=0.5,equalRatios=False):\n",
    "    X = df.drop(resCol,axis=1)\n",
    "    y = df[resCol]\n",
    "    fin = np.zeros(n)\n",
    "    classes = list(set(y))\n",
    "    perClass = [np.zeros(n) for val in classes]\n",
    "    for i in range(n):\n",
    "        if size < 1.0 and size > 0:\n",
    "            if equalRatios:\n",
    "                X_train, X_test, y_train, y_test = ms.train_test_split(X,y,train_size=size,stratify=y)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = ms.train_test_split(X,y,train_size=size)\n",
    "            fit = mod.fit(X_train,y_train)\n",
    "            res = fit.predict(X_test)\n",
    "            fin[i] = np.mean(y_test != res)\n",
    "            for j,val in enumerate(classes):\n",
    "                curr = X[y==val]\n",
    "                res = fit.predict(curr)\n",
    "                perClass[j][i] = np.mean(y[y==val] != res)\n",
    "        else:\n",
    "            raise ValueError(\"Size {0} is not in (0,1)\".format(size))\n",
    "    final1 = [np.mean(fin)]\n",
    "    final2 = [np.std(fin)] \n",
    "    for cla in perClass:\n",
    "        final1.append(np.mean(cla))\n",
    "        final2.append(np.std(cla))\n",
    "    return final1, final2\n",
    "\n",
    "def bootstrapErrorRate(mod,df,resCol,n=100):\n",
    "    fin = []\n",
    "    for i in range(n):\n",
    "        newdf = bootstrap(df)\n",
    "        errors = apparentErrorRate(mod,newdf,resCol)\n",
    "        fin.append(errors)\n",
    "    fin = np.transpose(fin)\n",
    "    final1 = [np.mean(f) for f in fin]\n",
    "    final2 = [np.std(f) for f in fin]\n",
    "    return final1 , final2\n",
    "\n",
    "def crossValidationErrorRate(mod,df,resCol,k=2,equalRatios=True,n=100):\n",
    "    errors = np.zeros(n)\n",
    "    classes = list(set(df[resCol]))\n",
    "    perClass = [np.zeros(n) for val in classes]\n",
    "    if equalRatios:\n",
    "        splitFunc = KFold_strat\n",
    "    else:\n",
    "        splitFunc = KFold\n",
    "    for i in range(n):\n",
    "        X_train,X_test,y_train,y_test = splitFunc(df.drop(resCol,axis=1),df[resCol],n_splits=k,shuffle=True)\n",
    "        temps = np.zeros(k)\n",
    "        classTemps = [np.zeros(k) for val in classes]\n",
    "        for j in range(k):\n",
    "            fit = mod.fit(X_train[j],y_train[j])\n",
    "            res = fit.predict(X_test[j])\n",
    "            temps[j] = np.mean(y_test[j] != res)\n",
    "            for l,val in enumerate(classes):\n",
    "                curr = X_test[j][y_test[j]==val]\n",
    "                res = fit.predict(curr)\n",
    "                classTemps[l][j] = np.mean(y_test[j][y_test[j]==val] != res)\n",
    "        errors[i] = np.mean(temps)\n",
    "        for l,val in enumerate(classes):\n",
    "            perClass[l][i] = np.mean(classTemps[l])\n",
    "    final1 = [np.mean(errors)]\n",
    "    final2 = [np.std(errors)]\n",
    "    final1.extend([np.mean(v) for v in perClass])\n",
    "    final2.extend([np.std(v) for v in perClass])\n",
    "    return final1, final2\n",
    "\n",
    "def resamplingComparison(model,df,resCol,k=5,n=100,size=0.5,equalRatios = True,stds=False):\n",
    "    classes = list(set(df[resCol]))\n",
    "    names = [\"Normal\",\"Bootstrap\",\"Training/Test, fraction = {0}\".format(size),\"Cross validation, k = {0}\".format(k)]\n",
    "    errors = [apparentErrorRate(model,df,resCol), \n",
    "              bootstrapErrorRate(model,df,resCol,n=n), \n",
    "              trainTestErrorRates(model,df,resCol,n=n,size=size,equalRatios=equalRatios),\n",
    "              crossValidationErrorRate(model,df,resCol,k=k,equalRatios=equalRatios,n=n)]\n",
    "    cols = [\"Global\"]\n",
    "    cols += [\"Class {0}\".format(c) for c in classes]\n",
    "    cols += [\"Global STD\"]\n",
    "    cols += [\"Class {0} STD\".format(c) for c in classes]\n",
    "    res = pd.DataFrame(columns = cols)\n",
    "    for i,tab in enumerate(errors):\n",
    "        res.loc[i] = tab[0] + tab[1]\n",
    "    res[\"method\"] = names\n",
    "    res = res[np.roll(res.columns.to_list(),1)]\n",
    "    if not(stds):\n",
    "        res = res.iloc[:,range(res.shape[1])[:-(len(classes)+1)]]\n",
    "    return res\n",
    "\n",
    "def modelComparison(models,dfs,resCol,errorFunc,names=[],stds=False):\n",
    "    classes = list(set(df[resCol]))\n",
    "    if type(dfs)!= list:\n",
    "        dfs = [dfs for m in models]\n",
    "    if not bool(names):\n",
    "        names = [str(mod).split(\"(\")[0] for mod in models]\n",
    "    elif len(names) != len(models) or len(dfs)!=len(models):\n",
    "        raise ValueError(\"length of names, models and dfs do not match\")\n",
    "    cols = [\"Global\"]\n",
    "    cols += [\"Class {0}\".format(c) for c in classes]\n",
    "    cols += [\"Global STD\"]\n",
    "    cols += [\"Class {0} STD\".format(c) for c in classes]\n",
    "    res = pd.DataFrame(columns = cols)\n",
    "    for i,mod in enumerate(models):\n",
    "        tab = errorFunc(mod,dfs[i],resCol)\n",
    "        res.loc[i] = tab[0] + tab[1]\n",
    "    res[\"Model\"] = names\n",
    "    res = res[np.roll(res.columns.to_list(),1)]\n",
    "    if not(stds):\n",
    "        res = res.iloc[:,range(res.shape[1])[:-(len(classes)+1)]]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   npreg  glu  bp  skin   bmi    ped  age type\n",
      "0      5   86  68    28  30.2  0.364   24   No\n",
      "1      7  195  70    33  25.1  0.163   55  Yes\n",
      "2      5   77  82    41  35.8  0.156   35   No\n",
      "3      0  165  76    43  47.9  0.259   26   No\n",
      "4      0  107  60    25  26.4  0.133   23   No\n"
     ]
    }
   ],
   "source": [
    "# Problema 1\n",
    "df = pd.read_csv(\"pimate.csv\")\n",
    "df = df.append(pd.read_csv(\"pimatr.csv\"),ignore_index=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataScaled(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(dual=False,max_iter=10**6),\n",
    "    SVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[\"original\"].copy()\n",
    "df1[\"ped*age\"] = df1[\"ped\"]*df1[\"age\"]\n",
    "df2 = data[\"original\"].copy()\n",
    "df2[\"ped*bp\"] = df2[\"ped\"]*df2[\"bp\"]\n",
    "df3 = data[\"original\"][[\"glu\",\"bmi\",\"ped\",\"age\",\"type\"]].copy()\n",
    "df3[\"age^2\"] = df3[\"age\"]*df3[\"age\"]\n",
    "df4 = data[\"original\"].copy()\n",
    "dfs = [df1,df2,df3,df4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                          method    Global  Class Yes  Class No\n",
       " 0                         Normal  0.204887   0.412429  0.101408\n",
       " 1                      Bootstrap  0.106391   0.200387  0.057833\n",
       " 2  Training/Test, fraction = 0.5  0.230075   0.411299  0.120000\n",
       " 3        Cross validation, k = 5  0.212756   0.417841  0.110423,\n",
       "                           method    Global  Class Yes  Class No\n",
       " 0                         Normal  0.219925   0.344633  0.157746\n",
       " 1                      Bootstrap  0.120301   0.175263  0.093684\n",
       " 2  Training/Test, fraction = 0.5  0.239098   0.361582  0.167887\n",
       " 3        Cross validation, k = 5  0.231927   0.350349  0.172958,\n",
       "                           method    Global  Class Yes  Class No\n",
       " 0                         Normal  0.206767   0.389831  0.115493\n",
       " 1                      Bootstrap  0.106579   0.186202  0.064244\n",
       " 2  Training/Test, fraction = 0.5  0.214286   0.380791  0.121690\n",
       " 3        Cross validation, k = 5  0.204542   0.384381  0.114930,\n",
       "                           method    Global  Class Yes  Class No\n",
       " 0                         Normal  0.216165   0.480226  0.084507\n",
       " 1                      Bootstrap  0.109023   0.248980  0.039634\n",
       " 2  Training/Test, fraction = 0.5  0.227820   0.492655  0.085634\n",
       " 3        Cross validation, k = 5  0.223657   0.493810  0.089014]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = [resamplingComparison(models[i],dfs[i],\"type\",n=5) for i in range(len(models))]\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "names = [\"Analisis de Discriminante Lineal\",\"Naive Bayes\",\"Regresión Logística\",\"Support Vector Machine\"]\n",
    "errors = [apparentErrorRate,lambda model,df,resCol: bootstrapErrorRate(model,df,resCol,n=n), \n",
    "              lambda model,df,resCol : trainTestErrorRates(model,df,resCol,n=n,size=0.75,equalRatios=True),\n",
    "              lambda model,df,resCol : crossValidationErrorRate(model,df,resCol,k=5,equalRatios=True,n=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function apparentErrorRate at 0x7f7849376c80>\n",
      "<function <lambda> at 0x7f784939a6a8>\n",
      "<function <lambda> at 0x7f784939a620>\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for err in errors[:-1]:\n",
    "    print(str(err))\n",
    "    res.append(modelComparison(models,dfs,\"type\",err,names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                              Model    Global  Class Yes  Class No\n",
       " 0  Analisis de Discriminante Lineal  0.204887   0.412429  0.101408\n",
       " 1                       Naive Bayes  0.219925   0.344633  0.157746\n",
       " 2               Regresión Logística  0.206767   0.389831  0.115493\n",
       " 3            Support Vector Machine  0.216165   0.480226  0.084507,\n",
       "                               Model    Global  Class Yes  Class No\n",
       " 0  Analisis de Discriminante Lineal  0.101107   0.198908  0.052251\n",
       " 1                       Naive Bayes  0.113115   0.173037  0.083392\n",
       " 2               Regresión Logística  0.100558   0.190955  0.055965\n",
       " 3            Support Vector Machine  0.108150   0.237657  0.044203,\n",
       "                               Model    Global  Class Yes  Class No\n",
       " 0  Analisis de Discriminante Lineal  0.215353   0.409910  0.106304\n",
       " 1                       Naive Bayes  0.233895   0.347921  0.170062\n",
       " 2               Regresión Logística  0.208105   0.383921  0.114377\n",
       " 3            Support Vector Machine  0.223835   0.487627  0.087504]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = \"p{3cm}\"\n",
    "for col in res[0].columns:\n",
    "    tab += \"|c\"\n",
    "res[0].to_latex(buf=os.path.join(\"tarea\",\"41-apparent.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[1].to_latex(buf=os.path.join(\"tarea\",\"41-boot.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[2].to_latex(buf=os.path.join(\"tarea\",\"41-traintest.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  AngPec  AMI  QWave  QWavecode  STcode  STchange  SuffHeartF  \\\n",
      "1    1       1    1      0          1       1         0           0   \n",
      "2    1       0    1      0          1       1         0           0   \n",
      "3    0       1    0      0          1       1         0           0   \n",
      "4    1       1    1      0          1       0         0           0   \n",
      "5    1       1    1      0          1       0         0           0   \n",
      "\n",
      "   Hypertrophi  Hyperchol  Smoker  Inherit  Heartfail CAD  \n",
      "1            0          0       0        0          0  No  \n",
      "2            0          0       0        0          0  No  \n",
      "3            0          0       0        0          0  No  \n",
      "4            0          0       0        0          0  No  \n",
      "5            0          0       0        0          0  No  \n"
     ]
    }
   ],
   "source": [
    "# Problema 2\n",
    "df = pd.read_csv(\"cad1.csv\",index_col=0)\n",
    "resCol=\"CAD\"\n",
    "dfCoded = df.copy()\n",
    "for col in df.columns: \n",
    "    if col!=resCol and df[col].dtype==np.dtype(\"O\"):\n",
    "        dfCoded[col] = df[col].astype(\"category\").cat.codes\n",
    "print(dfCoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(dual=False,max_iter=10**6),\n",
    "    SVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfCoded.copy()\n",
    "df1[\"Sex*AMI\"] = df1[\"Sex\"]*df1[\"AMI\"]\n",
    "df2 = dfCoded[[\"AngPec\",\"AMI\",\"STcode\",\"STchange\",\"Hyperchol\",\"CAD\"]].copy()\n",
    "df3 = dfCoded.copy()\n",
    "dfs = [df1,df2,df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "names = [\"Naive Bayes\",\"Regresión Logística\",\"Support Vector Machine\"]\n",
    "errors = [apparentErrorRate,\n",
    "              lambda model,df,resCol : trainTestErrorRates(model,df,resCol,n=n,size=0.75,equalRatios=True),\n",
    "              lambda model,df,resCol : crossValidationErrorRate(model,df,resCol,k=5,equalRatios=True,n=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function apparentErrorRate at 0x7f7849376c80>\n",
      "<function <lambda> at 0x7f784939a9d8>\n",
      "<function <lambda> at 0x7f78493a09d8>\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for err in errors:\n",
    "    print(str(err))\n",
    "    res.append(modelComparison(models,dfs,\"CAD\",err,names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = \"p{3cm}\"\n",
    "for col in res[0].columns:\n",
    "    tab += \"|c\"\n",
    "res[0].to_latex(buf=os.path.join(\"tarea\",\"42-apparent.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[1].to_latex(buf=os.path.join(\"tarea\",\"42-traintest.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[2].to_latex(buf=os.path.join(\"tarea\",\"42-crossval.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Weight  Fglucose  GlucoseInt  InsulinResp  InsulineResist  Class\n",
      "Patient                                                                  \n",
      "1          0.81        80         356          124              55      3\n",
      "2          0.95        97         289          117              76      3\n",
      "3          0.94       105         319          143             105      3\n",
      "4          1.04        90         356          199             108      3\n",
      "5          1.00        90         323          240             143      3\n"
     ]
    }
   ],
   "source": [
    "# Problema 3\n",
    "df = pd.read_csv(\"Glucose1.txt\",index_col=\"Patient\")\n",
    "#df[\"Class\"] = df[\"Class\"].astype(\"O\")\n",
    "data = dataScaled(df)\n",
    "print(data[\"original\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpredict = data[\"original\"][[\"InsulinResp\",\"Class\"]].copy()\n",
    "interactions = [\"Fglucose*InsulinResp\",\"GlucoseInt*InsulinResp\"]\n",
    "for inter in interactions:\n",
    "    columns = inter.split(\"*\")\n",
    "    modpredict[inter] = data[\"original\"][columns].product(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "names = [\"Regresión logística\"]\n",
    "errors = [apparentErrorRate,lambda model,df,resCol: bootstrapErrorRate(model,df,resCol,n=n), \n",
    "              lambda model,df,resCol : trainTestErrorRates(model,df,resCol,n=n,size=0.75,equalRatios=True),\n",
    "              lambda model,df,resCol : crossValidationErrorRate(model,df,resCol,k=5,equalRatios=True,n=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function apparentErrorRate at 0x7f7849376c80>\n",
      "<function <lambda> at 0x7f7847334620>\n",
      "<function <lambda> at 0x7f78473347b8>\n",
      "<function <lambda> at 0x7f7847334840>\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for err in errors:\n",
    "    print(str(err))\n",
    "    res.append(modelComparison([LogisticRegression(dual=False,max_iter=10**6)],[modpredict],\"Class\",err,names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = \"p{3cm}\"\n",
    "for col in res[0].columns:\n",
    "    tab += \"|c\"\n",
    "res[0].to_latex(buf=os.path.join(\"tarea\",\"43-apparent.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[1].to_latex(buf=os.path.join(\"tarea\",\"43-boot.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[2].to_latex(buf=os.path.join(\"tarea\",\"43-traintest.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)\n",
    "res[3].to_latex(buf=os.path.join(\"tarea\",\"43-crossval.tex\"),float_format=\"{:0.4f}\".format,index=False,column_format=tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
